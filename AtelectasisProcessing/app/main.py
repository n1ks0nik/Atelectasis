import os
import asyncio
import logging
import json
from aiokafka import AIOKafkaConsumer, AIOKafkaProducer
from aiokafka.errors import KafkaConnectionError, GroupCoordinatorNotAvailableError, KafkaError
from aiokafka.admin import AIOKafkaAdminClient, NewTopic

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

KAFKA_BOOTSTRAP = os.getenv("KAFKA_BOOTSTRAP", "kafka:9092")
TOPIC_RAW = os.getenv("TOPIC_RAW", "raw-images")
TOPIC_PROC = os.getenv("TOPIC_PROC", "inference-results")
GROUP_ID = "proc-service-group"


async def wait_for_kafka_ready(bootstrap_servers, max_retries=15, delay=5):
    """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ Kafka —á–µ—Ä–µ–∑ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–¥—é—Å–µ—Ä–∞"""

    for attempt in range(max_retries):
        try:
            # –ü—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–¥—é—Å–µ—Ä
            producer = AIOKafkaProducer(
                bootstrap_servers=bootstrap_servers,
                request_timeout_ms=5000,
                connections_max_idle_ms=10000
            )

            await producer.start()
            logger.info(f"‚úÖ Kafka is ready! Connection successful")
            await producer.stop()
            return True

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Kafka not ready (attempt {attempt + 1}/{max_retries}): {type(e).__name__}: {e}")
            await asyncio.sleep(delay)

    raise RuntimeError("‚ùå Kafka not ready after maximum retries")


async def start_with_retries(component, max_retries=10, delay=3):
    """–ó–∞–ø—É—Å–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
    for attempt in range(max_retries):
        try:
            await component.start()
            logger.info(f"‚úÖ Component started successfully")
            return
        except (KafkaConnectionError, GroupCoordinatorNotAvailableError, KafkaError) as e:
            logger.warning(f"‚ö†Ô∏è Failed to start component (attempt {attempt + 1}/{max_retries}): {e}")
            await asyncio.sleep(delay)

    raise RuntimeError("‚ùå Cannot start component after retries")


async def ensure_topics(bootstrap, topics):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ–ø–∏–∫–æ–≤ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç"""
    admin = AIOKafkaAdminClient(bootstrap_servers=bootstrap)
    await start_with_retries(admin, max_retries=5)

    try:
        existing = await admin.list_topics()
        to_create = [
            NewTopic(name=topic, num_partitions=1, replication_factor=1)
            for topic in topics if topic not in existing
        ]

        if to_create:
            await admin.create_topics(to_create)
            logger.info(f"‚úÖ Topics created: {[t.name for t in to_create]}")
        else:
            logger.info("‚úÖ All topics already exist")
    finally:
        await admin.close()


async def process_loop():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    logger.info("üöÄ Starting processing service...")

    # –ñ–¥–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ Kafka
    await wait_for_kafka_ready(KAFKA_BOOTSTRAP)

    # –°–æ–∑–¥–∞–µ–º —Ç–æ–ø–∏–∫–∏
    await ensure_topics(KAFKA_BOOTSTRAP, [TOPIC_RAW, TOPIC_PROC])

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
    logger.info("‚è≥ Waiting for system stabilization...")
    await asyncio.sleep(10)

    # –°–æ–∑–¥–∞–µ–º consumer –∏ producer
    consumer = AIOKafkaConsumer(
        TOPIC_RAW,
        bootstrap_servers=KAFKA_BOOTSTRAP,
        group_id=GROUP_ID,
        auto_offset_reset='earliest',
        enable_auto_commit=True,
        auto_commit_interval_ms=1000,
        consumer_timeout_ms=1000
    )

    producer = AIOKafkaProducer(
        bootstrap_servers=KAFKA_BOOTSTRAP,
        acks='all'
    )

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
    await start_with_retries(consumer)
    await start_with_retries(producer)

    logger.info("‚úÖ Processing service ready, waiting for messages...")

    try:
        while True:
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                msg_batch = await consumer.getmany(timeout_ms=1000, max_records=10)

                if not msg_batch:
                    continue

                for topic_partition, messages in msg_batch.items():
                    for msg in messages:
                        logger.info(f"üì® Processing message from {topic_partition}, offset: {msg.offset}")

                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                        raw_data = msg.value
                        result_dict = {
                            "processed": True,
                            "size": len(raw_data),
                            "timestamp": asyncio.get_event_loop().time(),
                            "message_offset": msg.offset,
                            "topic": msg.topic,
                            "partition": msg.partition
                        }
                        result = json.dumps(result_dict).encode('utf-8')

                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        await producer.send_and_wait(TOPIC_PROC, result)
                        logger.info(f"‚úÖ Message processed and sent to {TOPIC_PROC}")

            except GroupCoordinatorNotAvailableError as e:
                logger.warning(f"‚ö†Ô∏è GroupCoordinator not available: {e}, retrying...")
                await asyncio.sleep(5)
                continue
            except Exception as e:
                logger.error(f"‚ùå Error in processing loop: {e}")
                await asyncio.sleep(5)
                continue

    except KeyboardInterrupt:
        logger.info("üõë Shutting down processing service...")
    finally:
        await consumer.stop()
        await producer.stop()
        logger.info("‚úÖ Processing service stopped")


if __name__ == "__main__":
    try:
        asyncio.run(process_loop())
    except KeyboardInterrupt:
        logger.info("üëã Processing service terminated by user")