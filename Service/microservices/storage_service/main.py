import os
import asyncio
import logging
import json
from pathlib import Path
from dotenv import load_dotenv
from aiokafka import AIOKafkaConsumer, AIOKafkaProducer
from aiokafka.errors import KafkaConnectionError, GroupCoordinatorNotAvailableError, KafkaError
from aiokafka.admin import AIOKafkaAdminClient, NewTopic

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# .env
current_dir = Path(__file__).resolve().parent
parent_dir = current_dir.parent.parent
env_path = parent_dir / '.env'
load_dotenv(dotenv_path=env_path)
KAFKA_BOOTSTRAP = os.getenv("KAFKA_BOOTSTRAP", "kafka:9092")
TOPIC_RAW = os.getenv("TOPIC_RAW", "raw-images")
TOPIC_PROC = os.getenv("TOPIC_PROC", "inference-results")
GROUP_ID = "store-service-group"


async def wait_for_kafka_ready(bootstrap_servers, max_retries=15, delay=5):
    """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ Kafka —á–µ—Ä–µ–∑ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–¥—é—Å–µ—Ä–∞"""

    for attempt in range(max_retries):
        try:
            # –ü—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–¥—é—Å–µ—Ä
            producer = AIOKafkaProducer(
                bootstrap_servers=bootstrap_servers,
                request_timeout_ms=5000,
                connections_max_idle_ms=10000
            )

            await producer.start()
            logger.info(f"‚úÖ Kafka is ready! Connection successful")
            await producer.stop()
            return True

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Kafka not ready (attempt {attempt + 1}/{max_retries}): {type(e).__name__}: {e}")
            await asyncio.sleep(delay)

    raise RuntimeError("‚ùå Kafka not ready after maximum retries")


async def start_with_retries(component, max_retries=10, delay=3):
    """–ó–∞–ø—É—Å–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
    for attempt in range(max_retries):
        try:
            await component.start()
            logger.info(f"‚úÖ Component started successfully")
            return
        except (KafkaConnectionError, GroupCoordinatorNotAvailableError, KafkaError) as e:
            logger.warning(f"‚ö†Ô∏è Failed to start component (attempt {attempt + 1}/{max_retries}): {e}")
            await asyncio.sleep(delay)

    raise RuntimeError("‚ùå Cannot start component after retries")


async def ensure_topics(bootstrap, topics):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ–ø–∏–∫–æ–≤ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç"""
    admin = AIOKafkaAdminClient(bootstrap_servers=bootstrap)
    await start_with_retries(admin, max_retries=5)

    try:
        existing = await admin.list_topics()
        to_create = [
            NewTopic(name=topic, num_partitions=1, replication_factor=1)
            for topic in topics if topic not in existing
        ]

        if to_create:
            await admin.create_topics(to_create)
            logger.info(f"‚úÖ Topics created: {[t.name for t in to_create]}")
        else:
            logger.info("‚úÖ All topics already exist")
    finally:
        await admin.close()


async def store_loop():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ö—Ä–∞–Ω–µ–Ω–∏—è"""
    logger.info("üöÄ Starting storage service...")

    # –ñ–¥–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ Kafka
    await wait_for_kafka_ready(KAFKA_BOOTSTRAP)

    # –°–æ–∑–¥–∞–µ–º —Ç–æ–ø–∏–∫–∏
    await ensure_topics(KAFKA_BOOTSTRAP, [TOPIC_RAW, TOPIC_PROC])

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
    logger.info("‚è≥ Waiting for system stabilization...")
    await asyncio.sleep(10)

    # –°–æ–∑–¥–∞–µ–º consumer
    consumer = AIOKafkaConsumer(
        TOPIC_PROC,
        bootstrap_servers=KAFKA_BOOTSTRAP,
        group_id=GROUP_ID,
        auto_offset_reset='earliest',
        enable_auto_commit=True,
        auto_commit_interval_ms=1000,
        consumer_timeout_ms=1000
    )

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
    await start_with_retries(consumer)

    logger.info("‚úÖ Storage service ready, waiting for results...")

    try:
        while True:
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                msg_batch = await consumer.getmany(timeout_ms=1000, max_records=10)

                if not msg_batch:
                    continue

                for topic_partition, messages in msg_batch.items():
                    for msg in messages:
                        logger.info(f"üì® Received result from {topic_partition}, offset: {msg.offset}")

                        payload = msg.value

                        try:
                            # –ü—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON
                            result_data = json.loads(payload.decode('utf-8'))
                            logger.info(f"üíæ Storing result: {json.dumps(result_data, indent=2)}")

                            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                            # –Ω–∞–ø—Ä–∏–º–µ—Ä: await save_to_database(result_data)

                        except (json.JSONDecodeError, UnicodeDecodeError) as e:
                            logger.warning(f"‚ö†Ô∏è Failed to parse result as JSON: {e}")
                            logger.info(f"üíæ Raw result: {payload[:100]}...")  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 100 –±–∞–π—Ç

            except GroupCoordinatorNotAvailableError as e:
                logger.warning(f"‚ö†Ô∏è GroupCoordinator not available: {e}, retrying...")
                await asyncio.sleep(5)
                continue
            except Exception as e:
                logger.error(f"‚ùå Error in storage loop: {e}")
                await asyncio.sleep(5)
                continue

    except KeyboardInterrupt:
        logger.info("üõë Shutting down storage service...")
    finally:
        await consumer.stop()
        logger.info("‚úÖ Storage service stopped")


if __name__ == "__main__":
    try:
        asyncio.run(store_loop())
    except KeyboardInterrupt:
        logger.info("üëã Storage service terminated by user")